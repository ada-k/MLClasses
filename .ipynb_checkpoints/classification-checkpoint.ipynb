{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QN36ywNitODS",
        "vWww7ggXExhx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB-2FDMwpVFZ"
      },
      "source": [
        "## Classification\n",
        "\n",
        "> Type of supervised learning that specifies a class to which data elements belong.\n",
        "\n",
        "> **binary/binomial classification** - 2 classes involved.\n",
        "\n",
        "> **multi-class classification** - More than 2 classes invovlved. \n",
        "\n",
        "> **classification Algorithms**:\n",
        "* Linear Models:\n",
        "     * Logistic Regression.\n",
        "     * Support Vector Machines (SVM).\n",
        "* Non-linear Models:\n",
        "    * Naïve Bayes\n",
        "    * Decision Tree Classification\n",
        "    * Random Forest Classification.\n",
        "\n",
        "* ![spam classification](https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2019/11/classification.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1ZbJrd2wXkO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN36ywNitODS"
      },
      "source": [
        "### Logistic Regression\n",
        "\n",
        ">  A statistical method for predicting binary classes that computes the probability of an event occurence.\n",
        "\n",
        "> It is a special case of linear regression where the target variable is categorical in nature. It uses a log of odds as the dependent variable. Logistic Regression predicts the probability of occurrence of a binary event utilizing a logit function. (Can be extended for multi-class classification too).\n",
        "\n",
        "> It transforms its output using the logistic sigmoid function to return a probability value which can then be mapped to two or more discrete classes.\n",
        "\n",
        "> Multiple Linear Regression equation: **y = βo + β1x1 + β2x2 + … + βnxn + c.**\n",
        "\n",
        "> Sigmoid Function:\n",
        "     **p = 1/ (1 + e ^ −y)**   \n",
        "\n",
        "> Logistic Regression:\n",
        "     **p = 1/ (1 + e ^ −(βo + β1x1 + β2x2 + … + βnxn + c)**   \n",
        "\n",
        "> Properties of Logistic Regression:\n",
        "* The dependent variable in logistic regression follows Bernoulli Distribution (a special case of the two-point distribution, for which the possible outcomes need not be 0 and 1).\n",
        "* Estimation is done through maximum likelihood and not Least Squares method.\n",
        "\n",
        "> **Sigmoid Function**:\n",
        "* The sigmoid function, also called logistic function gives an ‘S’ shaped curve that can take any real-valued number and map it into a value between 0 and 1. If the curve goes to positive infinity, y predicted will become 1, and if the curve goes to negative infinity, y predicted will become 0. If the output of the sigmoid function is more than 0.5, we can classify the outcome as 1 or YES, and if it is less than 0.5, we can classify it as 0 or NO. \n",
        "\n",
        "> **MLE**:\n",
        "* The MLE is a \"likelihood\" maximization method, while OLS is a distance-minimizing approximation method. Maximizing the likelihood function determines the parameters that are most likely to produce the observed data. From a statistical point of view, MLE sets the mean and variance as parameters in determining the specific parametric values for a given model. This set of parameters can be used for predicting the data needed in a normal distribution.\n",
        "* Ordinary Least squares estimates are computed by fitting a regression line on given data points that has the minimum sum of the squared deviations (least square error). Both are used to estimate the parameters of a linear regression model.\n",
        "*  MLE assumes a joint probability mass function, while OLS doesn't require any stochastic (collection of random variables sindexed by some mathematical set) assumptions for minimizing distance.\n",
        "\n",
        "> Types of Logistic Regression:\n",
        "* **Binary Logistic Regression**: The target variable has only two possible outcomes such as Spam or Not Spam, Cancer or No Cancer.\n",
        "* **Multinomial Logistic Regression**: The target variable has three or more nominal categories such as predicting the type of Wine.\n",
        "* **Ordinal Logistic Regression**: the target variable has three or more ordinal categories such as restaurant or product rating from 1 to 5. (Review analysis).\n",
        "\n",
        "> Linear vs Logistic Visual Comparison:\n",
        "![Linear reg vs logistic reg](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281070/linear_vs_logistic_regression_edxw03.png)\n",
        "\n",
        "> **Pros**: doesn't require high computation power, easy to implement, easily interpretable, doesn't require scaling of features. \n",
        "\n",
        "> **Cons**: Logistic regression is not able to handle a large number of categorical features/variables. It is vulnerable to overfitting. Also, can't solve the non-linear problem with the logistic regression that is why it requires a transformation of non-linear features. Logistic regression will not perform well with independent variables that are not correlated to the target variable and are very similar or correlated to each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_7DduILAnMT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "KWKW6KEs_41T",
        "outputId": "15312ddb-3f31-4de2-ef23-eb142f5d7f9a"
      },
      "source": [
        "# loading diabetes dataset from kaggle\n",
        "data = pd.read_csv(\"/content/diabetes.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT61FcDrDYWK",
        "outputId": "cdcea9d8-7218-430b-dadd-689cbdb34303"
      },
      "source": [
        "data['Outcome'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBtaAN_WBKNt",
        "outputId": "fded8aca-4efa-442f-9236-72a2b39af509"
      },
      "source": [
        "#split dataset into independent and dependent variables\n",
        "X = data.drop(['Outcome'], axis = 1) # Independent/predictor variables\n",
        "y = data['Outcome'] # dependent/target variable\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((768, 8), (768,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNXdkgNqBbcb",
        "outputId": "fd646f47-afb8-4b01-b69d-24e78c06b5ad"
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((576, 8), (192, 8), (576,), (192,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6o64Kc0BgQR",
        "outputId": "bb7bc503-c8f8-4f2a-9def-647b62ec29ed"
      },
      "source": [
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "regressor = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "regressor.fit(x_train,y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred=regressor.predict(x_test)\n",
        "\n",
        "y_pred[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWww7ggXExhx"
      },
      "source": [
        "### Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9WqlCieE0io"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAm0nK7QE0rW"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxCYJVhzE46p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOwKgfIXE19U"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "> **Confusion Matrix**: A confusion matrix is a table used to evaluate the performance of a classification model. You can also visualize the performance of an algorithm. The fundamental of a confusion matrix is the number of correct and incorrect predictions are summed up class-wise.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W93NToWQGrcx"
      },
      "source": [
        "# import the metrics class\n",
        "from sklearn import metrics\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzxiaRfQHIRU"
      },
      "source": [
        "> **Accuracy**: (True positives + True Negatives) / Total Predictions\n",
        "\n",
        "> **Precision**: Precision is about being precise, i.e., how accurate your model is. In other words, you can say, when a model makes a prediction, how often it is correct. In your prediction case, when the Logistic Regression model predicted patients are going to suffer from diabetes, the patients will suffer/have 71% of the time.\n",
        "\n",
        "> **Recall**: If there are patients who have diabetes in the test set and your Logistic Regression model can identify it 59% of the time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua7oJKoGG-cX",
        "outputId": "36459624-7617-4da1-e741-2a14a7373a77"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7916666666666666\n",
            "Precision: 0.7115384615384616\n",
            "Recall: 0.5967741935483871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Oxdv5rGwe5"
      },
      "source": [
        "> **ROC Curve** - Receiver Operating Characteristic(ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "cBQB8puFHm0M",
        "outputId": "8a129121-1b00-4bf8-a5f0-c4133a67cded"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred_proba = regressor.predict_proba(x_test)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)  # area under the roc curve\n",
        "plt.plot(fpr, tpr, label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_zem_ImIB-R"
      },
      "source": [
        "AUC score for the case is 0.86. AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNClBLuOIE7c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}